{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(r\"C:\\Firstendtoendproject\\notebooks\\data\\GemstonePricePrediction.csv\")\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(labels=[\"price\"], axis=1)\n",
    "y = data[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values for each categorical column\n",
    "unique_carat_values = X['carat'].unique()\n",
    "unique_cut_values = X['cut'].unique()\n",
    "unique_color_values = X['color'].unique()\n",
    "unique_clarity_values = X['clarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "numerical_col = X.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom ranking for each ordinal variable\n",
    "cut_categories = ['Fair','Good','Very Good','Premium','Ideal']\n",
    "color_categories = ['D','E','F','G','H','I','J']\n",
    "clarity_categories = ['I1','SI2','SI1','VS2','VS1','WS2','WS1','IF', 'VVS1', 'VVS2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for numerical and categorical columns\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OrdinalEncoder', OrdinalEncoder(categories=[cut_categories, color_categories, clarity_categories]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer to combine the pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, numerical_col),\n",
    "    ('cat_pipeline', cat_pipeline, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the preprocessor to the training data and transform both the training and testing data\n",
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train), columns=preprocessor.get_feature_names_out())\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test), columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate the models\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Model Training Performance\n",
      "RMSE: 1230.5428399867646\n",
      "MAE: 834.5657751536753\n",
      "R2 score 90.68727752593722\n",
      "Accuracy score 90.68727752593722\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model Training Performance\n",
      "RMSE: 1231.8029968888798\n",
      "MAE: 836.5567165966868\n",
      "R2 score 90.6681940774303\n",
      "Accuracy score 90.6681940774303\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model Training Performance\n",
      "RMSE: 1230.7316884496001\n",
      "MAE: 834.8716560443316\n",
      "R2 score 90.68441890416784\n",
      "Accuracy score 90.68441890416784\n",
      "===================================\n",
      "\n",
      "\n",
      "ElasticNet\n",
      "Model Training Performance\n",
      "RMSE: 1623.8448986685437\n",
      "MAE: 1091.7042767422076\n",
      "R2 score 83.7829343099173\n",
      "Accuracy score 83.7829343099173\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "trained_model_list = []\n",
    "model_list = []\n",
    "r2_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae, mse, rmse, r2_square = evaluate_model(y_test, y_pred)\n",
    "\n",
    "     # Calculate R2 score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    # Calculate accuracy score (for regression models, this is not applicable, so we'll use R2 score as a proxy)\n",
    "    accuracy = r2\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print('R2 score', r2_square * 100)\n",
    "    print('Accuracy score', accuracy * 100)\n",
    "\n",
    "    r2_list.append(r2_square)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    trained_model_list.append(model)\n",
    "\n",
    "    print('=' * 35)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinearRegression(), Lasso(), Ridge(), ElasticNet()]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearRegression', 'Lasso', 'Ridge', 'ElasticNet']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9068727752593722, 0.906681940774303, 0.9068441890416784, 0.8378293430991729]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9068727752593722, 0.906681940774303, 0.9068441890416784, 0.8378293430991729]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
